In connection with my flirtation with the idea of a [juicier](https://www.sciencedirect.com/science/article/pii/S1875952118300879) data user experience, I'd like to explore building a [decision journal](https://fs.blog/decision-journal/). On the subject of juice, from the link above:

> We find that both None and Extreme amounts of juiciness lead to significantly decreased play time, significantly decreased player experience, significantly decreased intrinsic motivation, and significantly decreased performance relative to both Medium and High.

Have you seen the data tooling the kids are using nowadays? Vertex workbench?? Yuck. It's better than what our grandparents had, but we could do a whole lot better. Lets increase intrinsic motivation and performance if we can, right?

Back to the decision journal... I've felt since my Artsy days that organizations do an apalling job at leveraging data and decision science, and the reason is mostly about institutional learning. Statistics and probability theory are super hard and unintuitive, and people like feeling like they're following best practices so they tend to sort of be "data driven" to the point of being frozen in place.

I tend to think there are sort of two kinds of questions in startups.

There are really hard, intrinsic, important questions like "why are we here" and "what's our strategy" and "who do we serve" and "how are we different from our competitors" and "what do we value" and "how do we win". These take time to sift and percolate and ideate and filter, and no one really makes the mistake of being overly data driven here.

The other questions are.. still hard, but less existential? They're ones like, which feature should we prioritize, which vendor should we go with, what bugs do i need to fix right away vs. can hold off, etc.

... gotta go to sleep but the idea here is you build a place where people can (quickly, juicily) express their priors on a whole litany of daily decisions, which you then revisit on a regular basis for the purpose of calibration.

- who is correct but uninfluential?
- what inputs are regularly not helping inform good decisions?
- what are the similarities between repeated poor judgements?

Ex: We are going to build Feature A for the next two weeks:
_ We think it will achieve X
_ Pros: - data from 2 user studies
_ Cons: -
_ Person 1 thinks this is a reasonable good idea (p density) \* Person 2 thinks its a pretty neutral idea

... repeat this for 30 decisions over a year... then revisit.. if the information
were presented in the right way, you could learn a whole lot.

thought: Good ways to perform data capture will be the killer feature of future apps (bc ai).. data moats or bust.
